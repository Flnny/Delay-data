{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b91418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = torch.load('flight_data_dataset_train1.pt')\n",
    "test_dataset = torch.load('flight_data_dataset_test1.pt')\n",
    "valid_dataset = torch.load('flight_data_dataset_val1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e3044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06acb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=80000, shuffle=True, num_workers=20)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=80000, shuffle=True, num_workers=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19024c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8123e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取embedding信息\n",
    " \n",
    "import pickle\n",
    " \n",
    "f = open('new_feature_columns.pkl', 'rb')\n",
    "feature_columns = pickle.load(f)\n",
    "f.close()\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27adcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc170c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da51080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0170e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e296ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print('使用设备:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4509e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0e0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a918709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_feature_cols, sparse_feature_cols = feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc5936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07810e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FlightDelayRNN(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_size, num_layers, output_size):\n",
    "        super(FlightDelayRNN, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        \n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_'+str(i):nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        self.input_dim = len(self.dense_feature_cols) + len(self.sparse_feature_cols)*self.sparse_feature_cols[0]['embed_dim']\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.GRU(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2 if num_layers > 1 else 0  # 多层时启用dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :, :len(self.dense_feature_cols)], x[:, :, len(self.dense_feature_cols):]\n",
    "        sparse_inputs = sparse_inputs.long()\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:,:,i]) for i in range(sparse_inputs.shape[-1])]\n",
    "        sparse_embeds = torch.cat(sparse_embeds, dim=-1)\n",
    "        x = torch.cat([sparse_embeds, dense_inputs], dim=-1)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "hidden_size = 32  \n",
    "num_layers = 2  # RNN层数\n",
    "output_size = 2  \n",
    "\n",
    "model = FlightDelayRNN(feature_columns, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda274a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32  \n",
    "num_layers = 2  \n",
    "output_size = 2  \n",
    "\n",
    "model = FlightDelayCNN_LSTM(feature_columns, hidden_size, num_layers, output_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef4365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a431bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135981fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01951705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8b2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7927efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87f5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ec974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    #在序列中屏蔽不相关的项\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "X = torch.tensor([[1, 2, 3, 4], [4, 5, 6, 9]])\n",
    "sequence_mask(X, torch.tensor([1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \n",
    "    def __init__(self, pos_weight=4.5):\n",
    "        super(MaskedSoftmaxCELoss, self).__init__(reduction='none')\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        # 带权重张量，初始值为1\n",
    "        weights = torch.ones_like(label, dtype=torch.float)\n",
    "        \n",
    "        # 增加正类的权重\n",
    "        weights[label == 1] *= self.pos_weight\n",
    "        \n",
    "        # 只取序列的有效部分\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        \n",
    "        # 有效加权损失\n",
    "        unweighted_loss = super().forward(pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = unweighted_loss * weights\n",
    "        \n",
    "        total_loss = weighted_loss.sum()\n",
    "        total_valid_len = valid_len.sum()\n",
    "       # print(unweighted_loss, weighted_loss, total_loss, total_valid_len)\n",
    "        \n",
    "        \n",
    "        if total_valid_len > 0:\n",
    "            return total_loss / total_valid_len\n",
    "        else:\n",
    "            return torch.tensor(0.0).to(weighted_loss.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690c1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b997c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=0.001,          \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "criterion = MaskedSoftmaxCELoss()  \n",
    "\n",
    "CHECKPOINT_PATH = \"mlstm_model_checkpoint.pth\"\n",
    "BEST_MODEL_PATH = \"mlstm_best_model.pth\"\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "loss_history = []\n",
    "lr_history = []\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_epochs,  \n",
    "    eta_min=1e-6       \n",
    ")\n",
    "\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state'])  \n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    loss_history = checkpoint['train_loss_history']\n",
    "    lr_history = checkpoint['lr_history']  \n",
    "    print(f\"恢复训练：从第{start_epoch}轮开始，最佳验证损失：{best_val_loss:.4f}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        dense_feat, sparse_feat, two_labels, valid_lens = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        labels = two_labels[:,:,0]\n",
    "        \n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            features = torch.cat([dense_feat, sparse_feat], dim=-1)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels.long(), valid_lens)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / (progress_bar.n + 1)\n",
    "        progress_bar.set_postfix({\n",
    "            'train_loss': f\"{avg_loss:.4f}\",\n",
    "            'lr': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
    "        })\n",
    "\n",
    "    scheduler.step()  \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lr_history.append(current_lr)\n",
    "    print(f\"\\n当前学习率：{current_lr:.2e}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, val_batch in enumerate(test_dataloader):\n",
    "            if i >= 10000:  \n",
    "                break\n",
    "            v_dense, v_sparse, two_v_labels, v_lens = [x.to(device) for x in val_batch]\n",
    "            v_labels = two_v_labels[:,:,0]\n",
    "            v_features = torch.cat([v_dense, v_sparse], dim=-1)\n",
    "            v_outputs = model(v_features)\n",
    "            val_loss += criterion(v_outputs, v_labels.long(), v_lens).item()\n",
    "    \n",
    "    avg_val_loss = val_loss / min(10000, len(test_dataloader))\n",
    "    print(f\"验证损失：{avg_val_loss:.4f} | 历史最佳：{best_val_loss:.4f}\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict(), \n",
    "        'best_val_loss': best_val_loss,\n",
    "        'train_loss_history': loss_history,\n",
    "        'lr_history': lr_history  \n",
    "    }\n",
    "    torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f\"★ 发现新最佳模型，验证损失：{best_val_loss:.4f}\")\n",
    "\n",
    "torch.save(final_checkpoint, \"rnn0_final_model.pth\")\n",
    "print(f\"训练完成！最佳模型已保存至 {BEST_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3805e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954156e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f136f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Times New Roman',  \n",
    "    'font.size': 12,                  \n",
    "    'axes.labelsize': 14,              \n",
    "    'axes.linewidth': 1.2,             \n",
    "    'lines.linewidth': 2,              \n",
    "    'xtick.labelsize': 12,             \n",
    "    'ytick.labelsize': 12,             \n",
    "    'mathtext.fontset': 'stix',       \n",
    "    'savefig.dpi': 300,                \n",
    "    'figure.figsize': (8, 5)          \n",
    "})\n",
    "\n",
    "epochs = np.arange(len(lr_history))  \n",
    "max_lr = max(lr_history)\n",
    "min_lr = min(lr_history)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(epochs, lr_history, \n",
    "        color='#1f77b4',  \n",
    "        marker='o', \n",
    "        markersize=5,\n",
    "        markevery=int(len(epochs)/10),  \n",
    "        label='Learning Rate')\n",
    "\n",
    "\n",
    "ax.annotate(f'Initial LR: {max_lr:.1e}', \n",
    "           xy=(0, max_lr), \n",
    "           xytext=(5, max_lr*1.2),\n",
    "           arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
    "\n",
    "ax.annotate(f'Min LR: {min_lr:.1e}', \n",
    "           xy=(epochs[-1], min_lr), \n",
    "           xytext=(epochs[-1]-20, min_lr*1.5),\n",
    "           arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
    "\n",
    "\n",
    "ax.set_xlabel('Training Epochs', fontweight='bold')\n",
    "ax.set_ylabel('Learning Rate', fontweight='bold')\n",
    "ax.set_title('Cosine Annealing Learning Rate Schedule\\n(T_max=120 epochs)', \n",
    "            fontsize=14, pad=15)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.set_yscale('log')  \n",
    "\n",
    "\n",
    "secax = ax.secondary_xaxis('top')\n",
    "secax.set_xticks(np.linspace(0, len(epochs), 5))\n",
    "secax.set_xticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
    "secax.set_xlabel('Training Progress', fontweight='bold')\n",
    "\n",
    "\n",
    "ax.legend(frameon=True, \n",
    "         loc='upper right',\n",
    "         facecolor='white',\n",
    "         framealpha=0.8)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cosine_lr_schedule.pdf', format='pdf', bbox_inches='tight')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca5dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56202546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    'font.family': 'serif',               \n",
    "    'font.size': 12,                      \n",
    "    'axes.labelsize': 14,                 \n",
    "    'axes.linewidth': 1.5,                \n",
    "    'xtick.direction': 'in',              \n",
    "    'ytick.direction': 'in',              \n",
    "    'xtick.labelsize': 12,                \n",
    "    'ytick.labelsize': 12,                \n",
    "    'grid.linestyle': '--',              \n",
    "    'grid.alpha': 0.6,                    \n",
    "    'mathtext.fontset': 'stix',           \n",
    "    'savefig.dpi': 300,                   \n",
    "    'savefig.bbox': 'tight'               \n",
    "})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))   \n",
    "ax.plot(\n",
    "    range(1, len(loss_history)+1), \n",
    "    loss_history, \n",
    "    marker='o', \n",
    "    markersize=6,\n",
    "    linewidth=2,\n",
    "    color='#1f77b4',                      \n",
    "    markeredgecolor='k',                  \n",
    "    markeredgewidth=0.5\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel('Epoch', fontweight='bold') \n",
    "ax.set_ylabel('Loss', fontweight='bold')\n",
    "ax.set_title('Training Loss Progression', fontsize=16, pad=15)  \n",
    "ax.grid(True, which='both', alpha=0.6)    \n",
    "\n",
    "\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(2))  \n",
    "ax.yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(2))  \n",
    "ax.tick_params(which='minor', length=3, width=1)           \n",
    "\n",
    "\n",
    "plt.savefig('training_loss.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flight_model(device, \n",
    "                     feature_columns,\n",
    "                     hidden_size,\n",
    "                     num_layers,\n",
    "                     output_size,\n",
    "                     model_path=BEST_MODEL_PATH):\n",
    "\n",
    "    \n",
    "    model = FlightDelayRNN(\n",
    "        feature_columns=feature_columns,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=output_size\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ecc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import (accuracy_score, recall_score, precision_score, \n",
    "                           f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  \n",
    "    all_logits, all_labels, all_valid_lens = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            dense_feat, sparse_feat, two_labels, valid_lens = [x.to(device) for x in batch]\n",
    "            labels = two_labels[:,:,0]\n",
    "            feature = torch.cat([dense_feat, sparse_feat], dim=-1)\n",
    "            logits = model(feature)\n",
    "            \n",
    "            all_logits.append(logits.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_valid_lens.append(valid_lens.cpu())\n",
    "\n",
    "    logits = torch.cat(all_logits, dim=0).numpy()\n",
    "    labels = torch.cat(all_labels, dim=0).numpy()\n",
    "    valid_lens = torch.cat(all_valid_lens, dim=0).numpy()\n",
    "\n",
    "    position_mask = (np.arange(logits.shape[1]) < valid_lens[:, None])\n",
    "    \n",
    "    valid_probs = torch.softmax(torch.from_numpy(logits), dim=-1)[..., 1].numpy()\n",
    "    final_probs = valid_probs[position_mask].flatten()\n",
    "    final_labels = labels[position_mask].flatten()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(final_labels, final_probs)\n",
    "    J = tpr - fpr  \n",
    "    optimal_idx = np.argmax(J)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(final_labels, final_probs)\n",
    "    except ValueError:\n",
    "        auc = 0.5\n",
    "\n",
    "    pred_labels = (final_probs >= optimal_threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(final_labels, pred_labels),\n",
    "        \"Precision\": precision_score(final_labels, pred_labels, zero_division=0),\n",
    "        \"Recall\": recall_score(final_labels, pred_labels, zero_division=0),\n",
    "        \"F1\": f1_score(final_labels, pred_labels),\n",
    "        \"AUC\": auc\n",
    "    }, final_probs, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107af5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61afadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_flight_model(\n",
    "    device=device,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    output_size=output_size\n",
    ")\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                            batch_size=80000, \n",
    "                            shuffle=False, num_workers=20)\n",
    "val_dataloader = DataLoader(valid_dataset, \n",
    "                           batch_size=80000, \n",
    "                           shuffle=False, num_workers=20)\n",
    "test_dataloader = DataLoader(test_dataset,  \n",
    "                            batch_size=80000,\n",
    "                            shuffle=False, num_workers=20)\n",
    "\n",
    "train_metrics, _, _ = evaluate_model(model, train_dataloader, device)\n",
    "val_metrics, _, _ = evaluate_model(model, val_dataloader, device)\n",
    "test_metrics, final_probs, final_labels = evaluate_model(model, test_dataloader, device)  \n",
    "\n",
    "\n",
    "print(\"\\n{:<15} {:<10} {:<10} {:<10}\".format(\"Metric\", \"Train\", \"Val\", \"Test\"))\n",
    "for key in train_metrics:\n",
    "    print(\"{:<15} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
    "        key + \":\", \n",
    "        train_metrics[key], \n",
    "        val_metrics[key],\n",
    "        test_metrics[key]  \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dd430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818dd52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e19aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820aac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1dda9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f3441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37b26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb10b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080752b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c93261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
