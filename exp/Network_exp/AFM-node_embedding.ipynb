{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4757d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data.utils import makedirs, save_info, load_info\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print('使用设备:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import GraphConv\n",
    "class VGAEModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden1_dim, hidden2_dim):\n",
    "        super(VGAEModel, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "\n",
    "        layers = [\n",
    "            GraphConv(\n",
    "                self.in_dim,\n",
    "                self.hidden1_dim,\n",
    "                activation=F.relu,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "            GraphConv(\n",
    "                self.hidden1_dim,\n",
    "                self.hidden2_dim,\n",
    "                activation=lambda x: x,\n",
    "                allow_zero_in_degree=True,\n",
    "            ),\n",
    "        ]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def encoder(self, g, features):\n",
    "        h = self.layers[0](g, features)\n",
    "        #print(h.isnan().any())\n",
    "        self.mean = self.layers[1](g, h)\n",
    "        #print(self.mean.isnan().any())\n",
    "        self.log_std = self.layers[2](g, h)\n",
    "        #print(self.log_std.isnan().any())\n",
    "        gaussian_noise = torch.randn(features.size(0), self.hidden2_dim)\n",
    "        \n",
    "        sampled_z = self.mean + gaussian_noise * torch.exp(self.log_std)\n",
    "        \n",
    "        #print(sampled_z.isnan().any())\n",
    "        return sampled_z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        adj_rec = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "        #adj_rec = torch.nn.functional.sigmoid(torch.matmul(z, z.t()))\n",
    "        return adj_rec\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        z = self.encoder(g, features)\n",
    "        print(z.shape)\n",
    "        adj_rec = self.decoder(z)\n",
    "        print(adj_rec.shape)\n",
    "        print(adj_rec)\n",
    "        return adj_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76c233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17869dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdad79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e761fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "class MyDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        self.sparse_feat_names = ['MONTH', 'DAY_OF_WEEK', 'CRS_ARR_TIME_HOUR', 'CRS_DEP_TIME_HOUR', 'ORIGIN_LEVEL', 'DEST_LEVEL', 'ORIGIN_LABEL', 'DEST_LABEL','OP_CARRIER_LABEL']\n",
    "        self.dense_feat_names = ['O_TEMP', 'D_TEMP', 'O_PRCP', 'D_PRCP', 'O_WSPD', 'D_WSPD', 'DISTANCE']\n",
    "        super().__init__(name=\"my_dataset\")\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "        graphs = []\n",
    "\n",
    "        start_date = date(2016, 1, 1)\n",
    "        end_date = date(2016, 12, 30)\n",
    "        delta = timedelta(days=1)\n",
    "        \n",
    "        min_values, max_values = None, None\n",
    "        \n",
    "        while start_date <= end_date:\n",
    "            # 根据日期生成文件名\n",
    "            file_name = \"2016/graph\" + start_date.strftime(\"%Y%m%d\") + \".dgl\"\n",
    "            (g,), _ = dgl.load_graphs(file_name)\n",
    "\n",
    "\n",
    "            \n",
    "            #标签编码和归一化\n",
    "            \n",
    "            g.ndata['MONTH'] = g.ndata['MONTH'] - 1\n",
    "            g.ndata['DAY_OF_WEEK'] = g.ndata['DAY_OF_WEEK'] - 1\n",
    "            g.ndata['ORIGIN_LEVEL'][[torch.isnan(g.ndata['ORIGIN_LEVEL'])]] = 2\n",
    "            g.ndata['ORIGIN_LEVEL'] = g.ndata['ORIGIN_LEVEL'] - 1\n",
    "            g.ndata['DEST_LEVEL'][[torch.isnan(g.ndata['DEST_LEVEL'])]] = 2\n",
    "            g.ndata['DEST_LEVEL'] = g.ndata['DEST_LEVEL'] - 1\n",
    "\n",
    "            tensors = [g.ndata[name] for name in self.sparse_feat_names]\n",
    "            g.ndata['sparse_feat'] = torch.cat(tensors, dim=1)\n",
    "                        \n",
    "            \n",
    "            tensors = [g.ndata[name] for name in self.dense_feat_names]\n",
    "            g.ndata['dense_feat'] = torch.cat(tensors, dim=1)\n",
    "            #mms = MinMaxScaler()\n",
    "            #g.ndata['dense_feat'] = torch.from_numpy(mms.fit_transform(g.ndata['dense_feat'].numpy()))\n",
    "            g.ndata['dense_feat'][torch.isnan(g.ndata['dense_feat'])] = 0\n",
    "            \n",
    "            # 如果是第一个图，直接设置最小值和最大值\n",
    "            if min_values is None and max_values is None:\n",
    "                min_values = torch.min(g.ndata['dense_feat'], dim=0)[0]\n",
    "                max_values = torch.max(g.ndata['dense_feat'], dim=0)[0]\n",
    "            else:\n",
    "                # 更新最小值和最大值\n",
    "                min_values = torch.min(torch.stack((min_values, torch.min(g.ndata['dense_feat'], dim=0)[0])), dim=0)[0]\n",
    "                max_values = torch.max(torch.stack((max_values, torch.max(g.ndata['dense_feat'], dim=0)[0])), dim=0)[0]\n",
    "            \n",
    "            #print(min_values,max_values)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            #bins = [0, 15] # 设置分界点\n",
    "            bins = [15]\n",
    "            new_label = np.digitize(g.ndata['label'], bins) # 返回每个元素所属的区间，从1开始\n",
    "            g.ndata['label'] = torch.from_numpy(new_label)\n",
    "            #g.ndata['label'] = g.ndata['label'].reshape(-1)\n",
    "\n",
    "            graphs.append(g)\n",
    "            start_date += delta\n",
    "\n",
    "\n",
    "            \n",
    "        for g in graphs:\n",
    "            \n",
    "            g.ndata['dense_feat'] = (g.ndata['dense_feat'] - min_values) / (max_values - min_values)\n",
    "            print(g.ndata['dense_feat'])\n",
    "            g.ndata['embedding'] = self.get_embedding(g)\n",
    "            \n",
    "        \n",
    "        self.graphs = graphs    \n",
    "    \n",
    "    def get_embedding(self,g):\n",
    "        vgae_model = VGAEModel(in_dim=7, hidden1_dim=16, hidden2_dim=8)\n",
    "        vgae_model = vgae_model.to('cpu')\n",
    "        vgae_model.load_state_dict(torch.load('./vgae/node_embedding.pth'))\n",
    "        #print(g.ndata['dense_feat'],g)\n",
    "        node_embedding = vgae_model.encoder(g,g.ndata['dense_feat'])\n",
    "        return node_embedding    \n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "    def __getitem__(self, i):\n",
    "        # 返回第i个图\n",
    "        return self.graphs[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回图的数量\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def save(self):\n",
    "        graph_path = os.path.join(self.save_path, 'delay_class.bin')\n",
    "        save_graphs(str(graph_path), self.graphs)\n",
    "\n",
    "    def has_cache(self):\n",
    "        graph_path = os.path.join(self.save_path, 'delay_class.bin')\n",
    "        return os.path.exists(graph_path)\n",
    "\n",
    "    def load(self):\n",
    "        graphs, label_dict = load_graphs(os.path.join(self.save_path, 'delay_class.bin'))\n",
    "        self.graphs = graphs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(days):\n",
    "    rand_schedule = np.random.RandomState(seed=42).permutation(range(len(dataset))).tolist()\n",
    "    train_idx = rand_schedule[0:200]\n",
    "    test_idx = rand_schedule[200:266]\n",
    "    valid_idx = rand_schedule[266:365]\n",
    "    return train_idx, test_idx, valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f06dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40618676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6515918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12a3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1d002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx, valid_idx = split(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66ef18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7779f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(dataset,idx):\n",
    "    sub_data = torch.utils.data.Subset(dataset, idx)\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "    for i in tqdm(range(len(sub_data)), desc='Processing'):\n",
    "        sparse_feat = sub_data[i].ndata['sparse_feat']\n",
    "        print(sparse_feat.shape)\n",
    "        dense_feat = sub_data[i].ndata['dense_feat']\n",
    "        embedding_feat = sub_data[i].ndata['embedding']\n",
    "        feat = torch.cat([dense_feat, sparse_feat], dim =-1)\n",
    "        label_list.append(sub_data[i].ndata['label'])\n",
    "        feat_list.append(feat)\n",
    "    return torch.cat(feat_list,dim=0),torch.cat(label_list,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx, val_idx = split(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ee6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = table(dataset,train_idx)\n",
    "test_x, test_y = table(dataset,test_idx)\n",
    "val_x, val_y = table(dataset,val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4549fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.squeeze()\n",
    "test_y = test_y.squeeze()\n",
    "val_y = val_y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_dataset = TensorDataset(train_x,train_y)\n",
    "dl_test_dataset = TensorDataset(test_x,test_y)\n",
    "dl_val_dataset = TensorDataset(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370662a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71e86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de4236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl_train = DataLoader(dl_train_dataset, shuffle=True, batch_size=16000, num_workers=10)\n",
    "dl_val = DataLoader(dl_val_dataset, shuffle=True, batch_size=16000, num_workers=10)\n",
    "\n",
    "for x, y in iter(dl_train):\n",
    "    print(x.shape, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db3d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28135b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb72d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        super(Dnn, self).__init__()\n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        for linear in self.dnn_network:\n",
    "            x = linear(x)\n",
    "            x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39057af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_layer(nn.Module):\n",
    "    def __init__(self, att_units):\n",
    "        \"\"\"\n",
    "        att_units:[embed_dim, att_vector]\n",
    "        \"\"\"\n",
    "        super(Attention_layer, self).__init__()\n",
    "        self.att_w = nn.Linear(att_units[0], att_units[1])\n",
    "        self.att_dense = nn.Linear(att_units[1], 1)\n",
    "    def forward(self, bi_interation):\n",
    "        a = self.att_w(bi_interation)  #bi_iteation(None, field_num*(field_num-1)/2, embed_dim)\n",
    "        a = F.relu(a)\n",
    "        att_scores = self.att_dense(a) #（None，field_num*(field_num-1)/2, 1)\n",
    "        att_weight = F.softmax(att_scores, dim=1) #(None, field_num*(field_num-1)/2, 1)\n",
    "        att_out = torch.sum(att_weight * bi_interation, dim=1)\n",
    "        return att_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFM(nn.Module):\n",
    "    def __init__(self, feature_columns, mode, hidden_units, att_vector=8, dropout=0.5, useDNN=False):\n",
    "        super(AFM, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        self.mode = mode\n",
    "        self.useDNN = useDNN\n",
    "        \n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_'+str(i):nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim']) for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        if self.mode == 'att':\n",
    "            self.attention = Attention_layer([self.sparse_feature_cols[0]['embed_dim'], att_vector])\n",
    "        \n",
    "        if self.useDNN:\n",
    "            self.fea_num = len(self.dense_feature_cols) + self.sparse_feature_cols[0]['embed_dim']\n",
    "            hidden_units.insert(0, self.fea_num)\n",
    "            \n",
    "            self.bn = nn.BatchNorm1d(self.fea_num)\n",
    "            self.dnn_network = Dnn(hidden_units, dropout)\n",
    "            self.nn_final_linear = nn.Linear(hidden_units[-1], 1)\n",
    "        else:\n",
    "            self.fea_num = len(self.dense_feature_cols) + self.sparse_feature_cols[0]['embed_dim']\n",
    "            self.nn_final_linear = nn.Linear(self.fea_num, 1)\n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols)+8:]\n",
    "        sparse_inputs = sparse_inputs.long()\n",
    "\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embeds = torch.stack(sparse_embeds) # (field_num, None, embed_dim)\n",
    "        sparse_embeds = sparse_embeds.permute((1, 0, 2))\n",
    "\n",
    "        first = []\n",
    "        second = []\n",
    "        for f, s in itertools.combinations(range(sparse_embeds.shape[1]), 2):\n",
    "            first.append(f)\n",
    "            second.append(s)\n",
    "\n",
    "        p = sparse_embeds[:, first, :] \n",
    "        q = sparse_embeds[:, second, :] \n",
    "        bi_interaction = p * q\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            att_out = torch.sum(bi_interaction, dim=1) \n",
    "        elif self.mode == 'avg':\n",
    "            att_out = torch.mean(bi_interaction, dim=1) \n",
    "        else:\n",
    "            att_out = self.attention(bi_interaction)\n",
    "        \n",
    "        x = torch.cat([att_out, dense_inputs], dim=-1)\n",
    "        \n",
    "        if not self.useDNN:\n",
    "            outputs = torch.sigmoid(self.nn_final_linear(x))\n",
    "        else:\n",
    "            x = self.bn(x)\n",
    "            dnn_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "            outputs = torch.sigmoid(dnn_outputs)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231889da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da3f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f0c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取单个变量\n",
    " \n",
    "import pickle\n",
    " \n",
    "f = open('feature_columns.pckl', 'rb')\n",
    "feature_columns = pickle.load(f)\n",
    "f.close()\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92797131",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34178c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "print('使用设备:', device)\n",
    "\n",
    "dataset = MyDataset()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "hidden_units = [128, 64, 32]\n",
    "dnn_dropout = 0.\n",
    "model = AFM(feature_columns, 'att', hidden_units, dropout=dnn_dropout, useDNN=True)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './embed.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f796c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff28bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328e893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c047146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89746f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771796ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c1214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05815afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def auc(y_pred, y_true):\n",
    "    pred = y_pred.data\n",
    "    y = y_true.data\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "metric_func = auc\n",
    "metric_name = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2e99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4672f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c002a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "epochs = 50\n",
    "log_step_freq = 10\n",
    "\n",
    "dfhistory = pd.DataFrame(columns=['epoch', 'loss', metric_name, 'val_loss', 'val_'+metric_name])\n",
    "\n",
    "print('start_training.........')\n",
    "nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('========'*8 + '%s' %nowtime)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    metric_sum = 0.0\n",
    "    step = 1\n",
    "    \n",
    "    for step, (features, labels) in enumerate(dl_train, 1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        \n",
    "        \n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        features_resampled, labels_resampled = ros.fit_resample(features, labels)\n",
    "        features = torch.tensor(features_resampled)\n",
    "        labels = torch.tensor(labels_resampled)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    " \n",
    "\n",
    "        predictions = model(features);\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss_func(predictions, labels.float())\n",
    "        try:\n",
    "            metric = metric_func(predictions.float().cpu(), labels.float().cpu())\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        metric_sum += metric.item()\n",
    "        if step % log_step_freq == 0:\n",
    "            print((\"[step=%d] loss: %.3f, \" + metric_name + \": %.3f\") % (step, loss_sum/step, metric_sum/step));\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "    \n",
    "    for val_step, (features, labels) in enumerate(dl_val, 1):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(features)\n",
    "            val_loss = loss_func(predictions.float(), labels.float())\n",
    "            try:\n",
    "                val_metric = metric_func(predictions.float().cpu(), labels.float().cpu())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_metric_sum += val_metric.item()\n",
    "    \n",
    "\n",
    "    info = (epoch, loss_sum/step, metric_sum/step, val_loss_sum/val_step, val_metric_sum/val_step)\n",
    "    dfhistory.loc[epoch-1] = info\n",
    "    \n",
    "\n",
    "    print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "    nowtime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print('\\n' + '=========='* 8 + '%s' %nowtime)\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd66561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad18c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_metric(dfhistory,\"loss\")\n",
    "plot_metric(dfhistory,\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb700aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d9dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, val_data):\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_metric_sum = 0.0\n",
    "    val_step = 1\n",
    "    \n",
    "    y = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for val_step, (features, labels) in enumerate(val_data, 1):\n",
    "        print(val_step)\n",
    "        \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(features)\n",
    "            \n",
    "            print(predictions)\n",
    "            print(labels)\n",
    "            \n",
    "            y.append(labels)\n",
    "            y_pred.append(predictions)\n",
    "            \n",
    "            \n",
    "            val_loss = loss_func(predictions.float(), labels.float())\n",
    "            print\n",
    "            try:\n",
    "                val_metric = metric_func(predictions.float().cpu(), labels.float().cpu())\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        \n",
    "    val_metric_sum += val_metric\n",
    "        \n",
    "    return torch.concat(y).to('cpu'),torch.concat(y_pred).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_pred_pro = evaluation(model, dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b585a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import  precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f4453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9477ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y, y_pred_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c22033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_pro)\n",
    "th = 0.5\n",
    "y_pred = y_pred_pro.clone()\n",
    "print(y_pred)\n",
    "y_pred[y_pred>=th] = 1\n",
    "y_pred[y_pred<th] = 0\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pro.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in model.named_parameters():\n",
    "    print(par)\n",
    "    print(par[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655122d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d19f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.hist(y_pred_pro,bins=100)\n",
    " \n",
    "plt.title(\"data analyze\")\n",
    "plt.xlabel(\"height\")\n",
    "plt.ylabel(\"rate\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460672b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    print(k)\n",
    "    print(v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451268f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de196877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee736cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
